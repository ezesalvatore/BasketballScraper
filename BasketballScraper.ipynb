{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND9c7J9wr90Zy6qG+UFHzn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezesalvatore/BasketballScraper/blob/main/BasketballScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BasketBall Reference Uniform Scraper"
      ],
      "metadata": {
        "id": "x74FANU9a1s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project overview\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MrkFzG-ptG9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives\n",
        "- Extract players name, team and uniform number\n",
        "- Support wireframe development\n",
        "- Shows my webscraping expertises\n",
        "\n",
        "### Methods used\n",
        "- The webscraper being used is Beautiful Soup, since Basketball Reference is primarily build with HTML\n",
        "- This project also make sure that it follows Basketball Reference rate limiting and crawl-delay violations"
      ],
      "metadata": {
        "id": "PFbJwK4Xy8Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "snKzXEmfyrK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Makes a request to Basketball Reference\n",
        "import requests\n",
        "\n",
        "#How we are going to webscrape, able to parse through HTML to get the name, team, and uniform\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#Helps me with exporting a csv file\n",
        "import pandas as pd\n",
        "\n",
        "#Allows me to add delays\n",
        "import time\n",
        "\n",
        "#Data processing and cleaning\n",
        "import re\n",
        "\n",
        "#Creates url for web scraping\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "#Get rid of erros\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported\")"
      ],
      "metadata": {
        "id": "ykeBZbWRy3SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Session Setup"
      ],
      "metadata": {
        "id": "G7D5IX6C42yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_session():\n",
        "    \"\"\"\n",
        "    This function is setting up the sessions for web scraping. Making sure the headers are compliant.\n",
        "\n",
        "    \"\"\"\n",
        "    session = requests.Session()\n",
        "\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
        "        'Accept': 'text/html,application/xhtml+xml',\n",
        "        'Connection': 'keep-alive',\n",
        "    })\n",
        "\n",
        "    print(\"Session is created!\")\n",
        "\n",
        "    return session"
      ],
      "metadata": {
        "id": "HQSVR8cP46jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching Basketball Reference Data"
      ],
      "metadata": {
        "id": "Y7qOsl9f7f8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_basketball_data():\n",
        "    \"\"\"\n",
        "    Make single compliant request to Basketball Reference and following the robots.txt rules.\n",
        "\n",
        "    \"\"\"\n",
        "    url = \"https://www.basketball-reference.com/leagues/NBA_2025_numbers.html\"\n",
        "\n",
        "    session = setup_session()\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Robots.txt compliance: Crawl-delay: 3\n",
        "        time.sleep(3.0)\n",
        "\n",
        "        response = session.get(url, timeout=30)\n",
        "\n",
        "        print(f\"The request to: {url} has been sent out\")\n",
        "\n",
        "        if response.status_code == 429:\n",
        "            raise Exception(\"Rate limited - blocked for 24 hours\")\n",
        "\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(f\"Server Status: {response.status_code}\")\n",
        "\n",
        "        #HTML page returned\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Request failed: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        session.close()"
      ],
      "metadata": {
        "id": "qrXYEOj270k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping"
      ],
      "metadata": {
        "id": "FV-FwvHQ2sNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Scraping Strategy\n",
        "\n",
        "I will use the the CSS Selector to get the values from the html site\n",
        "\n",
        "**Uniform Number** : `div.data_grid_box table caption`\n",
        "<br>\n",
        "\n",
        "**Player Name**: `div.data_grid_box a[href*='/players/']`\n",
        "<br>\n",
        "\n",
        "**Team**: `span.desc a[href*='/teams/'] `\n",
        "\n"
      ],
      "metadata": {
        "id": "jTxlsmap26KI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zz0IZZF2Ch4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intergrate with other csv file"
      ],
      "metadata": {
        "id": "4E-m7Pc7n7ET"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmOYbS0boC2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}